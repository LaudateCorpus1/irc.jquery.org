[09:42:22] <DBRando> Hey guys
[09:44:33] <DBRando> Im working on an interesting problem - a user uploader solution for WP thats supposed to take care of 5k+ users per sheet. The importer relies mostly on jquery and ajax, then uses php to do the actual mapping. It works fine but server timeouts are a real concern for me. Is there a good way to somehow chunk this process - perhaps splitting the csv
[09:44:33] <DBRando> array into 50 smaller arrays then running the AJAX periodically per each array or something?
[10:00:50] <DBRando> I suppose a better question is
[10:01:19] <DBRando> Will running an ajax function multiple times with jquery each do anything at all to help stop server timeouts
[10:01:26] <DBRando> Or will it just cause an even bigger mess
[13:00:15] <DBRando> Hey guys I've done this plugin which uses jQuery and AJAX to import users into WP from a .csv.
[13:01:19] <DBRando> What this plugin does is it takes the CSV (usually these will have 5000 - 10000 lines), processes it, turns it into an array, then initiates an AJAX function which carries all the users to a php function where they are mapped
[13:01:35] <DBRando> My major concern are timeouts because a single php func tries processing the creation of 5000 users
[13:02:39] <DBRando> Is there still a risk of a timeout if I chunk this process? I thought of maybe splitting up the 5000 users into arrays of 20 each, then just doing multiple AJAX calls back-to-back for each chunk. Will this help?
[13:29:39] <DBRando> Okay maybe an easier one erh
[13:31:27] <DBRando> Can someone please help me with this - doing varname.split( /\r?\n/g ); will, from 492 lines in varname, create an array that has all these subarrays within: Array [0 - 99] Array [100 - 199] Array [200 - 299] Array [300 - 399] Array [400 - 492]
[13:31:58] <DBRando> What am I doing that is generating all these [x - y] subarrays? Can I somehow avoid these?
[13:38:16] <shoky> DBRando: it creates only one array. your console is probably just showing those slices , for display purposes
[13:38:29] <shoky> so you don't list more than 100 items at once
[13:39:10] <DBRando> I just figured it out - thanks shoky. It was actually just a very weird coincidence. For whatever reason something is off with my AJAX func which also stops it exactly at 100 lol
[13:39:18] <DBRando> So this split seemed like the cause of the bug
[13:39:33] <shoky> gotcha
[13:41:01] <DBRando> Hmm
[13:41:15] <DBRando> There is no code in between that could cause the bug
[13:41:32] <DBRando> Basically I carry over varname with $_POST into a php function
[13:41:56] <DBRando> Logging varname before the ajax results in a full array of 492 rows
[13:42:14] <DBRando> But logging what $_POST['varname'] actually fetches just puts out the first 100 rows
[13:42:26] <DBRando> Is there a limit to how much data can be carried over with $_POST or something?
[13:42:45] <shoky> no idea about php, but generally no
[13:46:03] <DBRando> This was down to post_max_size I think eughhh
[13:46:34] <DBRando> Okay, so I think the var needs to be chunked and then processed one by one
[13:46:37] <DBRando> Thanks shoky
